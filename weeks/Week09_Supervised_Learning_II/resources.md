# Week 9 Resources: Supervised Learning II - Advanced Models

## ðŸ“– Required Readings
- AIMA Chapter 18: Decision Trees, Ensemble Methods
- "Hands-On Machine Learning" Chapters 5-6, 7

## ðŸŽ¥ Video Resources
1. **[Decision Trees - StatQuest](https://www.youtube.com/watch?v=_L39rN6gz7Y)** (17 min)
2. **[Random Forests - StatQuest](https://www.youtube.com/watch?v=J4Wdy0Wc_xQ)** (10 min)
3. **[Support Vector Machines - MIT](https://www.youtube.com/watch?v=_PwhiWxHK8o)** (47 min)

## ðŸ’» Code Resources
- **scikit-learn**: [Decision Trees](https://scikit-learn.org/stable/modules/tree.html), [Ensembles](https://scikit-learn.org/stable/modules/ensemble.html), [SVM](https://scikit-learn.org/stable/modules/svm.html)
- **XGBoost**: `pip install xgboost` - Gradient boosting library

## ðŸ“Š Datasets
- UCI ML Repository
- Kaggle competitions for practice

## ðŸ“š Additional Reading
- "Pattern Recognition and Machine Learning" - Bishop, Chapter 7
- "Elements of Statistical Learning" - Chapter 9, 15

---
**ðŸ“Œ Focus:** Ensemble methods often win Kaggle competitions!
